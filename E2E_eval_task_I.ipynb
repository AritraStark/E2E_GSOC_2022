{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E2E_eval_task_I.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMytMtrzJIaToE+U/5SSwNF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AritraStark/E2E_GSOC_2022/blob/main/E2E_eval_task_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Common Task 1. Electron/photon classification**\n",
        "\n",
        "Datasets:\n",
        "\n",
        "https://cernbox.cern.ch/index.php/s/AtBT8y4MiQYFcgc (photons)\n",
        "\n",
        "https://cernbox.cern.ch/index.php/s/FbXw3V4XNyYB3oA (electrons)\n",
        "\n",
        "Description: 32x32 matrices (two channels - hit energy and time) for two classes of particles electrons and photons impinging on a calorimeter\n",
        "Please use a deep learning method of your choice to achieve the highest possible\n",
        "classification on this dataset (we ask that you do it both in Keras/Tensorflow and in PyTorch). Please provide a Jupyter notebook that shows your solution. The model yousubmit should have a ROC AUC score of at least 0.80."
      ],
      "metadata": {
        "id": "vsTucLeyQCsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the datasets from the links provided: "
      ],
      "metadata": {
        "id": "VBwlRChLQCga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cernbox.cern.ch/index.php/s/AtBT8y4MiQYFcgc/download -O photons.hdf5\n",
        "!wget https://cernbox.cern.ch/index.php/s/FbXw3V4XNyYB3oA/download -O electrons.hdf5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaIFeaOAc4bN",
        "outputId": "13927659-4b2e-4dc0-c8b0-bd1dff5758a2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-18 14:44:20--  https://cernbox.cern.ch/index.php/s/AtBT8y4MiQYFcgc/download\n",
            "Resolving cernbox.cern.ch (cernbox.cern.ch)... 128.142.53.35, 188.184.97.72, 128.142.53.28, ...\n",
            "Connecting to cernbox.cern.ch (cernbox.cern.ch)|128.142.53.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 119703858 (114M) [application/octet-stream]\n",
            "Saving to: ‘photons.hdf5’\n",
            "\n",
            "photons.hdf5        100%[===================>] 114.16M  21.9MB/s    in 6.1s    \n",
            "\n",
            "Last-modified header invalid -- time-stamp ignored.\n",
            "2022-03-18 14:44:29 (18.9 MB/s) - ‘photons.hdf5’ saved [119703858/119703858]\n",
            "\n",
            "--2022-03-18 14:44:29--  https://cernbox.cern.ch/index.php/s/FbXw3V4XNyYB3oA/download\n",
            "Resolving cernbox.cern.ch (cernbox.cern.ch)... 137.138.120.151, 128.142.170.17, 188.184.97.72, ...\n",
            "Connecting to cernbox.cern.ch (cernbox.cern.ch)|137.138.120.151|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 128927319 (123M) [application/octet-stream]\n",
            "Saving to: ‘electrons.hdf5’\n",
            "\n",
            "electrons.hdf5      100%[===================>] 122.95M  24.2MB/s    in 6.0s    \n",
            "\n",
            "Last-modified header invalid -- time-stamp ignored.\n",
            "2022-03-18 14:44:37 (20.5 MB/s) - ‘electrons.hdf5’ saved [128927319/128927319]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the imports:"
      ],
      "metadata": {
        "id": "KKyu1QBLc9Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbTnS9MPdCCm",
        "outputId": "fd575a2e-f1ca-4aee-cafc-f2de32962bcd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the data from the downloaded HDF5 files and combine the loaded datasets:"
      ],
      "metadata": {
        "id": "9X8Ns4T3ebZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_electron = np.array(h5py.File(\"electrons.hdf5\",'r').get(name=\"X\")[()])\n",
        "y_electron = np.array(h5py.File(\"electrons.hdf5\",'r').get(name=\"y\")[()])\n",
        "X_photon = np.array(h5py.File(\"photons.hdf5\",'r').get(name=\"X\")[()])\n",
        "y_photon = np.array(h5py.File(\"photons.hdf5\",'r').get(name=\"y\")[()])\n",
        "\n",
        "X_particles = np.concatenate((X_electron,X_photon),axis=0)\n",
        "y_particles = np.concatenate((y_electron,y_photon),axis=0)\n",
        "print(X_particles.shape,y_particles.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNhJPOwKeldg",
        "outputId": "4eb44bb6-6536-4ad8-d9f7-c593d896001b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(498000, 32, 32, 2) (498000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flattening the data: "
      ],
      "metadata": {
        "id": "_im73IfrZfuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stream_data = X_particles[:,:,:,0].reshape(-1,32*32)\n",
        "stream_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG_hh9yRZiEC",
        "outputId": "5b3e9b30-8446-4937-8df5-2baa86345b9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(498000, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomizing data:"
      ],
      "metadata": {
        "id": "33iGX-LnY-83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(48)\n",
        "rng_state = np.random.get_state()\n",
        "np.random.shuffle(stream_data)\n",
        "np.random.set_state(rng_state)\n",
        "np.random.shuffle(y_particles)"
      ],
      "metadata": {
        "id": "rwukmb7yZBgy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the data into training and testing sets ( I have split it in 80-20 as per instructions): "
      ],
      "metadata": {
        "id": "B_96cSfhb3G7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split( stream_data, y_particles, random_state=48, test_size=0.2 )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyDuWD1Sb6tY",
        "outputId": "17abb30f-3a1e-4558-e8e4-54709c945fee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the model:"
      ],
      "metadata": {
        "id": "AEYtfPYbco75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(256, activation = 'relu', input_shape =X_train.shape[1:]),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(256, activation = 'relu'),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(256, activation = 'relu'),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(256, activation = 'relu'),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "GjZA7FP8cyMg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining callbacks:"
      ],
      "metadata": {
        "id": "fEdVlpnygsgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath=\"classifier_weights2-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint1 = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint1]"
      ],
      "metadata": {
        "id": "9VM4NKsZgu8Z"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model and fitting it with testing data:"
      ],
      "metadata": {
        "id": "9SFMBIyAgZ2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "history = model.fit(X_train,  y_train, \n",
        "                    validation_split=0.2, \n",
        "                    epochs=200, \n",
        "                    batch_size=2000,\n",
        "                    callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "GBlYFXwGgf3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the results:"
      ],
      "metadata": {
        "id": "VLaz0XRbhHxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Accuracy of the model')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss metrics of the model')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6W9AXuCDhKPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the performance of the model on predictions:"
      ],
      "metadata": {
        "id": "zuK6QGdyhWip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch=np.argmax(history.history['val_accuracy'])\n",
        "best_acc=np.max(history.history['val_accuracy'])\n",
        "model.load_weights(f\"classifier_weights2-improvement-{best_epoch+1}-{best_acc:.2f}.hdf5\")\n",
        "predictions = model.predict(X_train)\n",
        "bin =[0 if p<0.5 else 1 for p in predictions]"
      ],
      "metadata": {
        "id": "dm2VGlYAiucb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P8Y71U6FixE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train,bin))\n",
        "roc_auc_score(y_train, bin)"
      ],
      "metadata": {
        "id": "sWfZcWBwjPje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**References :**\n",
        "\n",
        "\n",
        "1.   [Examining Electron and Photon Classification Using Convolutional Neural Networks\n",
        "Jonah Warner, Research Assistant\n",
        "Department of Physics, Carnegie Mellon University, Pittsburgh 15213](https://www.cmu.edu/ai-physics-institute/outreach/surp/images/2021/jonah-warner-poster.pdf)\n",
        "2.   [End-to-End Event Classification of High-Energy\n",
        "Physics Data\n",
        "M Andrews\n",
        ", M Paulini\n",
        ", S Gleyzer\n",
        ", B Poczos](https://indico.cern.ch/event/567550/papers/2629451/files/7515-end-end-event_v4.pdf)\n",
        "3.   [Calorimetry with Deep Learning: Particle\n",
        "Classification, Energy Regression, and Simulation for\n",
        "High-Energy Physics\n",
        "Federico Carminati, Gulrukh Khattak, Maurizio Pierini\n",
        "CERN](https://dl4physicalsciences.github.io/files/nips_dlps_2017_15.pdf)\n",
        "4.  [Electron/Photon Ambiguity Resolution Using Neural\n",
        "networks For ATLAS Experiment\n",
        "Nutthawara Buatthaisong, Khon Kaen University, Thailand\n",
        "](https://www.desy.de/f/students/2019/reports/nutthawara.buatthaisong.pdf)\n"
      ],
      "metadata": {
        "id": "Z1wnCtwaPVGx"
      }
    }
  ]
}